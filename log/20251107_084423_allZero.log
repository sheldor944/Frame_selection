nohup: ignoring input
=== Step 1: Running change_score.py on all_zero ===
anno_path: ./datasets/videomme/include_frame_idx.json
=== Step 2: Running insert_frame_num.py ===
=== Step 3: Running evaluation with lmms_eval ===
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[32m2025-11-07 08:44:27[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to INFO[0m
[32m2025-11-07 08:44:28[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': './results/all_zero'}[0m
[32m2025-11-07 08:44:28[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['videomme'][0m
[32m2025-11-07 08:44:28[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m161[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.
force sample: False
Loaded LLaVA model: /home/hpc4090/miraj/AKS/AKS/llava_eval/LLaVA-NeXT-Video-7B-Qwen2
Loading vision tower: google/siglip-so400m-patch14-384
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:05,  1.93s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.68s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.60s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.23s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.40s/it]
Model Class: LlavaQwenForCausalLM
[32m2025-11-07 08:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36m__init__[0m:[36m223[0m - [1mUsing single device: cuda:0[0m
Generating test split:   0%|          | 0/2700 [00:00<?, ? examples/s]Generating test split:   0%|          | 0/2700 [00:00<?, ? examples/s]
Generating test split:   0%|          | 0/2700 [00:00<?, ? examples/s]Generating test split:   0%|          | 0/2700 [00:00<?, ? examples/s]
Generating test split:   0%|          | 0/2700 [00:00<?, ? examples/s]Generating test split:   0%|          | 0/2700 [00:00<?, ? examples/s]
Generating test split:   0%|          | 0/2700 [00:00<?, ? examples/s]Generating test split:   0%|          | 0/2700 [00:00<?, ? examples/s]
Generating test split:   0%|          | 0/2700 [00:00<?, ? examples/s]Generating test split:   0%|          | 0/2700 [00:00<?, ? examples/s]
Traceback (most recent call last):
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/datasets/builder.py", line 1834, in _prepare_split_single
    writer.write_table(table)
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/datasets/arrow_writer.py", line 714, in write_table
    pa_table = table_cast(pa_table, self._schema)
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/datasets/table.py", line 2272, in table_cast
    return cast_table_to_schema(table, schema)
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/datasets/table.py", line 2218, in cast_table_to_schema
    raise CastError(
datasets.table.CastError: Couldn't cast
video_id: string
duration: string
domain: string
sub_category: string
url: string
videoID: string
question_id: string
task_type: string
question: string
options: list<item: string>
  child 0, item: string
answer: string
frame_idx: list<item: int64>
  child 0, item: int64
frame_num: int64
use_topk: bool
-- schema metadata --
pandas: '{"index_columns": [], "column_indexes": [], "columns": [{"name":' + 1807
to
{'video_id': Value('string'), 'duration': Value('string'), 'domain': Value('string'), 'sub_category': Value('string'), 'url': Value('string'), 'videoID': Value('string'), 'question_id': Value('string'), 'task_type': Value('string'), 'question': Value('string'), 'options': List(Value('string')), 'answer': Value('string')}
because column names don't match

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/tenacity/__init__.py", line 470, in __call__
    result = fn(*args, **kwargs)
  File "/home/hpc4090/miraj/AKS/AKS/llava_eval/lmms-eval/lmms_eval/api/task.py", line 1054, in download
    self.dataset = datasets.load_dataset(
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/datasets/load.py", line 1417, in load_dataset
    builder_instance.download_and_prepare(
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/datasets/builder.py", line 897, in download_and_prepare
    self._download_and_prepare(
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/datasets/builder.py", line 973, in _download_and_prepare
    self._prepare_split(split_generator, **prepare_split_kwargs)
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/datasets/builder.py", line 1705, in _prepare_split
    for job_id, done, content in self._prepare_split_single(
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/datasets/builder.py", line 1836, in _prepare_split_single
    raise DatasetGenerationCastError.from_cast_error(
datasets.exceptions.DatasetGenerationCastError: An error occurred while generating the dataset

All the data files must have the same columns, but at some point there are 3 new columns ({'frame_num', 'use_topk', 'frame_idx'})

This happened while the json dataset builder was generating data using

/home/hpc4090/miraj/AKS/AKS/datasets/videomme/include_frame_idx.json

Please either edit the data files to have matching columns, or separate them into different configurations (see docs at https://hf.co/docs/hub/datasets-manual-configuration#multiple-configurations)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc4090/miraj/AKS/AKS/llava_eval/lmms-eval/lmms_eval/__main__.py", line 349, in cli_evaluate
    results, samples = cli_evaluate_single(args)
  File "/home/hpc4090/miraj/AKS/AKS/llava_eval/lmms-eval/lmms_eval/__main__.py", line 484, in cli_evaluate_single
    results = evaluator.simple_evaluate(
  File "/home/hpc4090/miraj/AKS/AKS/llava_eval/lmms-eval/lmms_eval/utils.py", line 536, in _wrapper
    return fn(*args, **kwargs)
  File "/home/hpc4090/miraj/AKS/AKS/llava_eval/lmms-eval/lmms_eval/evaluator.py", line 200, in simple_evaluate
    task_dict = get_task_dict(tasks, task_manager, task_type)
  File "/home/hpc4090/miraj/AKS/AKS/llava_eval/lmms-eval/lmms_eval/tasks/__init__.py", line 565, in get_task_dict
    task_name_from_string_dict = task_manager.load_task_or_group(
  File "/home/hpc4090/miraj/AKS/AKS/llava_eval/lmms-eval/lmms_eval/tasks/__init__.py", line 378, in load_task_or_group
    all_loaded_tasks = dict(collections.ChainMap(*map(load_fn, task_list)))
  File "/home/hpc4090/miraj/AKS/AKS/llava_eval/lmms-eval/lmms_eval/tasks/__init__.py", line 297, in _load_individual_task_or_group
    return _load_task(task_config, task=name_or_config)
  File "/home/hpc4090/miraj/AKS/AKS/llava_eval/lmms-eval/lmms_eval/tasks/__init__.py", line 267, in _load_task
    task_object = TaskObj(config=config, model_name=self.model_name)
  File "/home/hpc4090/miraj/AKS/AKS/llava_eval/lmms-eval/lmms_eval/api/task.py", line 724, in __init__
    self.download(self.config.dataset_kwargs)
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/tenacity/__init__.py", line 330, in wrapped_f
    return self(f, *args, **kw)
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/tenacity/__init__.py", line 467, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/tenacity/__init__.py", line 368, in iter
    result = action(retry_state)
  File "/home/hpc4090/miraj/AKS/AKS/llava/lib/python3.9/site-packages/tenacity/__init__.py", line 411, in exc_check
    raise retry_exc from fut.exception()
tenacity.RetryError: RetryError[<Future at 0x7a955435feb0 state=finished raised DatasetGenerationCastError>]
[32m2025-11-07 08:44:54[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m371[0m - [31m[1mError during evaluation: RetryError[<Future at 0x7a955435feb0 state=finished raised DatasetGenerationCastError>]. Please set `--verbosity=DEBUG` to get more information.[0m
=== Evaluation Complete ===
